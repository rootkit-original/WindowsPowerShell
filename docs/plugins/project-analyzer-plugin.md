# ğŸ“Š XKit Project Analyzer Plugin

## ğŸ“‹ VisÃ£o Geral

O **Project Analyzer Plugin** Ã© um dos plugins centrais do XKit v3.0, responsÃ¡vel por analisar a qualidade e estrutura de projetos em diretÃ³rios `.xkit`. Ele fornece anÃ¡lises detalhadas com pontuaÃ§Ã£o de qualidade, sugestÃµes de melhoria e insights inteligentes.

## ğŸ¯ Funcionalidades

### âœ¨ **AnÃ¡lise Completa de Projetos**
- ğŸ” **DetecÃ§Ã£o AutomÃ¡tica de Tipos**: Python, Node.js, Rust, Go, Java, C#, TypeScript
- ğŸ“Š **PontuaÃ§Ã£o de Qualidade**: Escala 0-10 baseada em mÃºltiplos critÃ©rios
- ğŸ¤– **AnÃ¡lise IA**: IntegraÃ§Ã£o com Gemini AI para insights avanÃ§ados
- ğŸ“ˆ **MÃ©tricas Detalhadas**: Tamanho, arquivos, documentaÃ§Ã£o, testes
- ğŸ”§ **SugestÃµes Inteligentes**: RecomendaÃ§Ãµes para melhorar o projeto

### ğŸ“ **DetecÃ§Ã£o Inteligente**
- âœ… **Arquivos Essenciais**: README, LICENSE, CONTRIBUTING, CHANGELOG
- ğŸ“š **DocumentaÃ§Ã£o**: Markdown, reStructuredText, AsciiDoc
- ğŸ§ª **Testes**: DetecÃ§Ã£o automÃ¡tica de frameworks de teste
- âš™ï¸ **ConfiguraÃ§Ã£o**: Package managers, build tools, CI/CD

### ğŸ—ï¸ **Arquitetura Plugin**
- ğŸ§© **Plugin Base**: Herda de `XKitCorePlugin`
- ğŸ“¡ **Event-Driven**: Publica eventos durante anÃ¡lise
- ğŸ”Œ **ServiÃ§os Integrados**: AI Service, Display Service
- ğŸ”„ **Hot Reload**: Suporta recarregamento dinÃ¢mico

## ğŸš€ Comandos DisponÃ­veis

### `analyze-project`
Executa anÃ¡lise completa de um projeto especÃ­fico.

```powershell
# Analisar projeto atual
xkit analyze-project

# Analisar projeto especÃ­fico
xkit analyze-project "C:\Users\Dev\MeuProjeto"
```

**SaÃ­da:**
- ğŸ“Š PontuaÃ§Ã£o geral (0-10)
- ğŸ“ Tipo de projeto detectado
- ğŸ“ˆ MÃ©tricas detalhadas
- ğŸ¤– Insights IA (se disponÃ­vel)
- âŒ Issues encontrados
- ğŸ’¡ SugestÃµes de melhoria

### `scan-xkit-projects`
Escaneia diretÃ³rio em busca de projetos `.xkit` e analisa todos.

```powershell
# Escanear diretÃ³rio atual
xkit scan-xkit-projects

# Escanear diretÃ³rio especÃ­fico
xkit scan-xkit-projects "C:\Users\Dev\Projetos"
```

**SaÃ­da:**
- ğŸ“‚ Lista de projetos encontrados
- ğŸ“Š Resumo de pontuaÃ§Ã£o para cada
- ğŸ¯ VisÃ£o geral comparativa

### `project-score`
Retorna apenas a pontuaÃ§Ã£o do projeto (Ãºtil para automaÃ§Ã£o).

```powershell
# Score do projeto atual
xkit project-score

# Score de projeto especÃ­fico  
xkit project-score "C:\Path\To\Project"
```

**SaÃ­da:**
- ğŸ“Š PontuaÃ§Ã£o numÃ©rica (0.0-10.0)

## ğŸ—ï¸ Arquitetura TÃ©cnica

### ğŸ“¦ **Estruturas de Dados**

#### `ProjectType` (Enum)
```python
class ProjectType(Enum):
    PYTHON = "python"
    NODE_JS = "nodejs" 
    RUST = "rust"
    GO = "go"
    JAVA = "java"
    C_SHARP = "csharp"
    JAVASCRIPT = "javascript"
    TYPESCRIPT = "typescript"
    UNKNOWN = "unknown"
```

#### `ProjectFile` (DataClass)
```python
@dataclass
class ProjectFile:
    name: str           # Nome do arquivo
    path: str           # Caminho completo
    size: int           # Tamanho em bytes
    is_essential: bool  # Ã‰ arquivo essencial?
    category: str       # Categoria (docs, config, source, test)
```

#### `ProjectMetrics` (DataClass)
```python
@dataclass
class ProjectMetrics:
    total_files: int        # Total de arquivos
    total_size: int         # Tamanho total
    documentation_files: int # Arquivos de documentaÃ§Ã£o
    config_files: int       # Arquivos de configuraÃ§Ã£o
    source_files: int       # Arquivos de cÃ³digo fonte
    test_files: int         # Arquivos de teste
    has_git: bool          # Tem controle Git?
    has_readme: bool       # Tem README?
    has_license: bool      # Tem LICENSE?
    has_contributing: bool # Tem CONTRIBUTING?
    has_tests: bool        # Tem testes?
```

#### `ProjectAnalysisResult` (DataClass)
```python
@dataclass
class ProjectAnalysisResult:
    project_path: str           # Caminho do projeto
    project_type: ProjectType   # Tipo detectado
    metrics: ProjectMetrics     # MÃ©tricas calculadas
    score: float               # PontuaÃ§Ã£o (0-10)
    issues: List[str]          # Problemas encontrados
    suggestions: List[str]     # SugestÃµes de melhoria
    files: List[ProjectFile]   # Lista de arquivos
    ai_insights: Optional[str] # Insights IA (opcional)
```

### ğŸ”§ **Algoritmo de PontuaÃ§Ã£o**

```python
# Sistema de pontuaÃ§Ã£o ponderada
base_score = 0.0

# Arquivos Essenciais (0-3 pontos)
if has_readme: base_score += 1.0
if has_license: base_score += 0.5  
if has_contributing: base_score += 0.5
if has_changelog: base_score += 0.5
if has_gitignore: base_score += 0.5

# CÃ³digo Fonte (0-3 pontos)  
source_ratio = source_files / total_files
base_score += min(3.0, source_ratio * 4.0)

# Testes (0-2 pontos)
if has_tests:
    test_ratio = test_files / source_files if source_files > 0 else 0
    base_score += min(2.0, test_ratio * 10.0)

# DocumentaÃ§Ã£o (0-1.5 pontos)
doc_ratio = documentation_files / total_files  
base_score += min(1.5, doc_ratio * 5.0)

# Estrutura (0-0.5 pontos)
if total_files >= 10: base_score += 0.5

# IA Bonus (0-1 ponto adicional)
if ai_available and project_follows_best_practices:
    base_score += ai_bonus_score

final_score = min(10.0, base_score)
```

### ğŸ” **DetecÃ§Ã£o de Tipos de Projeto**

```python
project_patterns = {
    ProjectType.PYTHON: [
        "requirements.txt", "setup.py", "pyproject.toml", 
        "Pipfile", "poetry.lock", "*.py"
    ],
    ProjectType.NODE_JS: [
        "package.json", "package-lock.json", "yarn.lock", "*.js"
    ],
    ProjectType.RUST: [
        "Cargo.toml", "Cargo.lock", "src/main.rs"
    ],
    ProjectType.GO: [
        "go.mod", "go.sum", "main.go", "*.go"  
    ],
    ProjectType.JAVA: [
        "pom.xml", "build.gradle", "gradlew", "*.java"
    ],
    ProjectType.C_SHARP: [
        "*.csproj", "*.sln", "project.json", "*.cs"
    ],
    ProjectType.TYPESCRIPT: [
        "tsconfig.json", "package.json", "*.ts"
    ]
}

def _detect_project_type(self, files: List[ProjectFile]) -> ProjectType:
    """Detecta o tipo do projeto baseado nos arquivos presentes"""
    file_names = [f.name.lower() for f in files]
    
    # Conta matches para cada tipo
    type_scores = {}
    for project_type, patterns in self.project_patterns.items():
        score = 0
        for pattern in patterns:
            if any(fnmatch.fnmatch(name, pattern) for name in file_names):
                score += 1
        type_scores[project_type] = score
    
    # Retorna o tipo com maior score
    if type_scores:
        return max(type_scores, key=type_scores.get)
    return ProjectType.UNKNOWN
```

## ğŸ¤– IntegraÃ§Ã£o IA

### **Gemini AI Service**
```python
async def _get_ai_insights(self, result: ProjectAnalysisResult) -> str:
    """ObtÃ©m insights de IA sobre o projeto"""
    
    prompt = f\"\"\"
    Analise este projeto {result.project_type.value}:
    
    ğŸ“Š MÃ©tricas:
    - Arquivos: {result.metrics.total_files}
    - Tamanho: {result.metrics.total_size} bytes
    - DocumentaÃ§Ã£o: {result.metrics.documentation_files}
    - Testes: {result.metrics.test_files}
    - Score Atual: {result.score}/10
    
    ğŸ” Issues: {', '.join(result.issues)}
    
    ForneÃ§a insights especÃ­ficos para melhorar este projeto.
    \"\"\"
    
    try:
        response = await self.ai_service.analyze(prompt)
        return response
    except Exception as e:
        self.log_warning(f"AI analysis failed: {e}")
        return None
```

### **SugestÃµes Inteligentes**
```python
def _generate_suggestions(self, result: ProjectAnalysisResult) -> List[str]:
    """Gera sugestÃµes baseadas na anÃ¡lise"""
    suggestions = []
    
    # README ausente
    if not result.metrics.has_readme:
        suggestions.append("ğŸ“– Adicionar README.md com descriÃ§Ã£o do projeto")
    
    # LICENSE ausente  
    if not result.metrics.has_license:
        suggestions.append("âš–ï¸ Adicionar arquivo LICENSE para definir termos de uso")
        
    # Testes insuficientes
    if result.metrics.test_files == 0:
        suggestions.append("ğŸ§ª Implementar testes unitÃ¡rios e de integraÃ§Ã£o")
        
    # DocumentaÃ§Ã£o insuficiente
    doc_ratio = result.metrics.documentation_files / result.metrics.total_files
    if doc_ratio < 0.1:
        suggestions.append("ğŸ“š Expandir documentaÃ§Ã£o do projeto")
        
    # Estrutura de diretÃ³rios
    if result.metrics.total_files < 5:
        suggestions.append("ğŸ—‚ï¸ Organizar cÃ³digo em estrutura de diretÃ³rios")
    
    return suggestions
```

## ğŸ“Š Sistema de Display

### **ExibiÃ§Ã£o de Resultados**
```python
async def _display_analysis_result(self, result: ProjectAnalysisResult):
    """Exibe resultado completo da anÃ¡lise"""
    
    # CabeÃ§alho
    self.display.section(f"ğŸ“Š AnÃ¡lise do Projeto: {os.path.basename(result.project_path)}")
    
    # InformaÃ§Ãµes bÃ¡sicas
    self.display.info(f"ğŸ“ Tipo: {result.project_type.value.upper()}")
    self.display.info(f"ğŸ“‚ Caminho: {result.project_path}")
    
    # PontuaÃ§Ã£o com cor
    score_emoji = "ğŸŸ¢" if result.score >= 7 else "ğŸŸ¡" if result.score >= 4 else "ğŸ”´"
    self.display.print_colored(
        f"{score_emoji} PontuaÃ§Ã£o: {result.score:.1f}/10",
        "success" if result.score >= 7 else "warning" if result.score >= 4 else "error"
    )
    
    # MÃ©tricas
    self.display.section("ğŸ“ˆ MÃ©tricas")
    print(f"  ğŸ“„ Total de arquivos: {result.metrics.total_files:,}")
    print(f"  ğŸ’¾ Tamanho total: {self._format_size(result.metrics.total_size)}")
    print(f"  ğŸ“š DocumentaÃ§Ã£o: {result.metrics.documentation_files}")
    print(f"  ğŸ§ª Testes: {result.metrics.test_files}")
    print(f"  ğŸ”§ ConfiguraÃ§Ã£o: {result.metrics.config_files}")
    print(f"  ğŸ’» CÃ³digo fonte: {result.metrics.source_files}")
    
    # Issues
    if result.issues:
        self.display.section("âŒ Problemas Encontrados")
        for issue in result.issues:
            print(f"  â€¢ {issue}")
    
    # SugestÃµes
    if result.suggestions:
        self.display.section("ğŸ’¡ SugestÃµes de Melhoria") 
        for suggestion in result.suggestions:
            print(f"  â€¢ {suggestion}")
    
    # Insights IA
    if result.ai_insights:
        self.display.section("ğŸ¤– Insights IA")
        print(f"  {result.ai_insights}")

def _format_size(self, size_bytes: int) -> str:
    """Formata tamanho em bytes para leitura humana"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if size_bytes < 1024.0:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024.0
    return f"{size_bytes:.1f} TB"
```

## ğŸ”§ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### **Registro do Plugin**
```python
# No plugin manager
plugin_manager.register_plugin(XKitProjectAnalyzerPlugin())

# VerificaÃ§Ã£o de dependÃªncias
required_services = ["ai_service", "display_service", "file_system"]
for service in required_services:
    if not plugin_manager.has_service(service):
        raise PluginDependencyError(f"Required service not available: {service}")
```

### **ConfiguraÃ§Ã£o**
```json
{
  "project_analyzer": {
    "enabled": true,
    "ai_integration": true,
    "max_file_scan": 10000,
    "timeout": 30,
    "score_thresholds": {
      "excellent": 8.0,
      "good": 6.0,
      "needs_improvement": 4.0
    }
  }
}
```

## ğŸ§ª Testes

### **Unit Tests**
```python
@pytest.mark.asyncio
async def test_project_type_detection():
    plugin = XKitProjectAnalyzerPlugin()
    
    # Test Python project detection
    files = [
        ProjectFile("requirements.txt", "/path/requirements.txt", 100, True, "config"),
        ProjectFile("main.py", "/path/main.py", 500, True, "source")
    ]
    
    project_type = plugin._detect_project_type(files)
    assert project_type == ProjectType.PYTHON

@pytest.mark.asyncio 
async def test_scoring_algorithm():
    plugin = XKitProjectAnalyzerPlugin()
    
    metrics = ProjectMetrics(
        total_files=10,
        total_size=5000,
        documentation_files=2,
        config_files=3,
        source_files=4,
        test_files=1,
        has_git=True,
        has_readme=True,
        has_license=True,
        has_contributing=False,
        has_tests=True
    )
    
    score = plugin._calculate_score(metrics)
    assert 6.0 <= score <= 8.0  # Expected range
```

### **Integration Tests**
```python
@pytest.mark.integration
async def test_full_project_analysis():
    # Criar projeto de teste
    test_project = create_test_project()
    
    plugin = XKitProjectAnalyzerPlugin()
    await plugin.initialize()
    
    # Executar anÃ¡lise
    result = await plugin.analyze_project(test_project.path)
    
    # Verificar resultado
    assert result.score > 0
    assert result.project_type != ProjectType.UNKNOWN
    assert len(result.files) > 0
    assert result.metrics.total_files > 0
```

## ğŸš€ Performance

### **OtimizaÃ§Ãµes**
- âš¡ **Scan AssÃ­ncrono**: Usa `asyncio` para scan paralelo de arquivos
- ğŸ¯ **Filtros Inteligentes**: Ignora diretÃ³rios desnecessÃ¡rios (node_modules, .git, __pycache__)
- ğŸ’¾ **Cache Inteligente**: Cache de resultados para anÃ¡lises repetidas
- ğŸ”„ **Lazy Loading**: Carrega dados conforme necessÃ¡rio

### **ConfiguraÃ§Ã£o de Performance**
```python
# ConfiguraÃ§Ãµes de performance
PERFORMANCE_CONFIG = {
    "max_concurrent_scans": 10,
    "max_file_size_mb": 100,
    "cache_duration_minutes": 30,
    "ignored_directories": [
        ".git", "node_modules", "__pycache__", 
        ".venv", "venv", "target", "build"
    ]
}
```

## ğŸ“š Exemplos de Uso

### **AnÃ¡lise Simples**
```python
# Usar o plugin programaticamente
plugin = XKitProjectAnalyzerPlugin()
await plugin.initialize()

result = await plugin.analyze_project("/path/to/project")
print(f"Score: {result.score}/10")
print(f"Type: {result.project_type}")
```

### **AnÃ¡lise em Lote**
```python
# Analisar mÃºltiplos projetos
projects = ["/project1", "/project2", "/project3"]
results = []

for project_path in projects:
    result = await plugin.analyze_project(project_path)
    results.append(result)

# Ordenar por score
results.sort(key=lambda x: x.score, reverse=True)
```

### **IntegraÃ§Ã£o com CI/CD**
```bash
#!/bin/bash
# Script de CI para verificar qualidade do projeto

score=$(xkit project-score)
if (( $(echo "$score >= 7.0" | bc -l) )); then
    echo "âœ… Project quality check passed: $score/10"
    exit 0
else
    echo "âŒ Project quality check failed: $score/10"
    echo "ğŸ’¡ Run 'xkit analyze-project' for suggestions"
    exit 1
fi
```

## ğŸ”— Links Relacionados

- ğŸ“– [Plugin Development Guide](../development/plugin-development.md)
- ğŸ—ï¸ [XKit Architecture](../architecture/README.md)
- ğŸ¤– [AI Service Documentation](../api/core-api.md#ai-service)
- ğŸ“¡ [Event System](../api/event-api.md)

---

**ğŸ“Š Project Analyzer Plugin** Ã© uma ferramenta essencial do XKit v3.0 para manter alta qualidade em projetos de desenvolvimento, fornecendo anÃ¡lises inteligentes e sugestÃµes prÃ¡ticas para melhoria contÃ­nua.